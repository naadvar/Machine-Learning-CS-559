{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fNOV2CEUrL3v",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "target_names = ['conan','jane']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mh3OgP9_0AMM",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#here we just read the text files into a dataframe\n",
    "\n",
    "jane = pd.read_fwf('jane.txt')\n",
    "conan = pd.read_fwf('conan.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3VNESkYaONZ7",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "b3a2dcb7-703c-4dca-ac5b-c0afe74a5f64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10385, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "57HCac5A0IpB",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#here we create labels for the authors, 0 -> Arthur Coanan, 1-> Jane Austen\n",
    "zero =  pd.DataFrame(np.zeros(conan.shape[0]))\n",
    "ones = pd.DataFrame(np.ones(jane.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rEMfG_KcKem4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#here we just add the labels to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "9FCYWJks50nr",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "conan=pd.concat([conan,zero],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Fw9yDEQs7CiM",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "jane = pd.concat([jane,ones],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3NLzSI3T6x4v",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "lSpke7HO_JfH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "jane.columns=['text','label']\n",
    "conan.columns = ['text','label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rNCYnhFbKl-8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "#now we concatenate botht the files for easier parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wZgBNECu_rYo",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "merge = pd.concat([jane,conan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bkMZ9kWI_6ye",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "merge = shuffle(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VljUoxqbZ2vn",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969.0
    },
    "outputId": "0a8f8a9a-47cd-4244-af1b-a3919ea5d3c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15184</th>\n",
       "      <td>stamp, for he had easy manners, excellent spir...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>A reverie succeeded this conviction--and when ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9214</th>\n",
       "      <td>\"There are four umbrellas up already. How I ha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39830</th>\n",
       "      <td>must return it by him.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33897</th>\n",
       "      <td>if you saw it. I dare not let my mother know h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66896</th>\n",
       "      <td>hear from him again. I earnestly pressed his c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>most fleeting glance of the front of the house...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44634</th>\n",
       "      <td>for the uncertain and unequal Amusements of th...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43787</th>\n",
       "      <td>were concerning Philippa and her Husband, the ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50657</th>\n",
       "      <td>de Bourgh she derived this comfort for Miss Bi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41410</th>\n",
       "      <td>his advances towards intimacy, especially to o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17369</th>\n",
       "      <td>should prevent us? Not these countenances, I a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53061</th>\n",
       "      <td>much civility on that lady's side the acquaint...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6748</th>\n",
       "      <td>\"Good heavens!\" I cried, \"this is a terrible i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>at the Cape, and in compliance with a promise ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16109</th>\n",
       "      <td>a very good grace, and would only say, \"Very w...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>to be you?\"</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>minute.  I know you will not be sorry to be of...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48884</th>\n",
       "      <td>do not make haste he will change his mind and ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22848</th>\n",
       "      <td>be long sorry for this day's transactions.\"</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>gone.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52937</th>\n",
       "      <td>more that might lead to the mention of her, ha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62385</th>\n",
       "      <td>when obliged to endure it. Her heart was harde...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50279</th>\n",
       "      <td>being so thin and so small. There was neither ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>again into the past, more exquisitely happy, p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50170</th>\n",
       "      <td>upstairs in a violent hurry, and calling loudl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44306</th>\n",
       "      <td>entirely forgot. I hate scandal and detest Chi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11647</th>\n",
       "      <td>Her greedy eye glanced rapidly over a page. Sh...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50199</th>\n",
       "      <td>At length there was nothing more to be said; t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59417</th>\n",
       "      <td>deception originated. Sometimes one is guided ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54484</th>\n",
       "      <td>his regiment at the end of a fortnight.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63051</th>\n",
       "      <td>\"Indeed I believe you,\" replied Elinor; \"but I...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29660</th>\n",
       "      <td>contracted her mind: I really believe, if she ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29301</th>\n",
       "      <td>Harriet could not long resist so delightful a ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62382</th>\n",
       "      <td>at a third could resist it with energy. In one...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59690</th>\n",
       "      <td>\"I think,\" replied Edward, \"that I may defy ma...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>never seemed considered by the others as havin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57501</th>\n",
       "      <td>sorry he was that she had taken a house at suc...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19890</th>\n",
       "      <td>chance--absolutely without chance or possibili...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51920</th>\n",
       "      <td>frequent discussion between her parents. Eliza...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37204</th>\n",
       "      <td>pigeon-pies and cold lamb, when a lame carriag...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51784</th>\n",
       "      <td>vanity she had not yet been able to reason awa...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44946</th>\n",
       "      <td>young Man was not unlike in character to that ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>to you.\"</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24642</th>\n",
       "      <td>his removal on board directly, that he might h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25688</th>\n",
       "      <td>Crawford went into Norfolk before or after the...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61584</th>\n",
       "      <td>\"By many--by some of whom you know nothing, by...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48449</th>\n",
       "      <td>been very imprudent, and has deserved to lose ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67187</th>\n",
       "      <td>She could not foresee that Colonel Brandon wou...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58273</th>\n",
       "      <td>which Sir John had been previously forming, we...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33322</th>\n",
       "      <td>to Ireland. Here, she must be leading a life o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41843</th>\n",
       "      <td>leaves her more to herself than she did, and I...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21292</th>\n",
       "      <td>she was not prevented from offering, nor you f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54584</th>\n",
       "      <td>what I have to tell you. I must confess myself...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46070</th>\n",
       "      <td>distinguished by his sisters. Jane was as much...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55612</th>\n",
       "      <td>were sensible of your own good, you would not ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40603</th>\n",
       "      <td>\"Good God!\" she cried.--\"Well!\"--Then having r...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13716</th>\n",
       "      <td>attention; and though latterly, from some hint...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31773</th>\n",
       "      <td>The plan was that she should be brought up for...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44473</th>\n",
       "      <td>and have very much distressed him. The alterat...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78261 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "15184  stamp, for he had easy manners, excellent spir...    1.0\n",
       "10305  A reverie succeeded this conviction--and when ...    1.0\n",
       "9214   \"There are four umbrellas up already. How I ha...    1.0\n",
       "39830                             must return it by him.    1.0\n",
       "33897  if you saw it. I dare not let my mother know h...    1.0\n",
       "66896  hear from him again. I earnestly pressed his c...    1.0\n",
       "7029   most fleeting glance of the front of the house...    0.0\n",
       "44634  for the uncertain and unequal Amusements of th...    1.0\n",
       "43787  were concerning Philippa and her Husband, the ...    1.0\n",
       "50657  de Bourgh she derived this comfort for Miss Bi...    1.0\n",
       "41410  his advances towards intimacy, especially to o...    1.0\n",
       "17369  should prevent us? Not these countenances, I a...    1.0\n",
       "53061  much civility on that lady's side the acquaint...    1.0\n",
       "6748   \"Good heavens!\" I cried, \"this is a terrible i...    0.0\n",
       "6634   at the Cape, and in compliance with a promise ...    1.0\n",
       "16109  a very good grace, and would only say, \"Very w...    1.0\n",
       "5839                                         to be you?\"    1.0\n",
       "6757   minute.  I know you will not be sorry to be of...    1.0\n",
       "48884  do not make haste he will change his mind and ...    1.0\n",
       "22848        be long sorry for this day's transactions.\"    1.0\n",
       "2716                                               gone.    0.0\n",
       "52937  more that might lead to the mention of her, ha...    1.0\n",
       "62385  when obliged to endure it. Her heart was harde...    1.0\n",
       "50279  being so thin and so small. There was neither ...    1.0\n",
       "6892   again into the past, more exquisitely happy, p...    1.0\n",
       "50170  upstairs in a violent hurry, and calling loudl...    1.0\n",
       "44306  entirely forgot. I hate scandal and detest Chi...    1.0\n",
       "11647  Her greedy eye glanced rapidly over a page. Sh...    1.0\n",
       "50199  At length there was nothing more to be said; t...    1.0\n",
       "59417  deception originated. Sometimes one is guided ...    1.0\n",
       "...                                                  ...    ...\n",
       "54484            his regiment at the end of a fortnight.    1.0\n",
       "63051  \"Indeed I believe you,\" replied Elinor; \"but I...    1.0\n",
       "29660  contracted her mind: I really believe, if she ...    1.0\n",
       "29301  Harriet could not long resist so delightful a ...    1.0\n",
       "62382  at a third could resist it with energy. In one...    1.0\n",
       "59690  \"I think,\" replied Edward, \"that I may defy ma...    1.0\n",
       "298    never seemed considered by the others as havin...    1.0\n",
       "57501  sorry he was that she had taken a house at suc...    1.0\n",
       "19890  chance--absolutely without chance or possibili...    1.0\n",
       "51920  frequent discussion between her parents. Eliza...    1.0\n",
       "37204  pigeon-pies and cold lamb, when a lame carriag...    1.0\n",
       "51784  vanity she had not yet been able to reason awa...    1.0\n",
       "44946  young Man was not unlike in character to that ...    1.0\n",
       "1906                                            to you.\"    0.0\n",
       "24642  his removal on board directly, that he might h...    1.0\n",
       "25688  Crawford went into Norfolk before or after the...    1.0\n",
       "61584  \"By many--by some of whom you know nothing, by...    1.0\n",
       "48449  been very imprudent, and has deserved to lose ...    1.0\n",
       "67187  She could not foresee that Colonel Brandon wou...    1.0\n",
       "58273  which Sir John had been previously forming, we...    1.0\n",
       "33322  to Ireland. Here, she must be leading a life o...    1.0\n",
       "41843  leaves her more to herself than she did, and I...    1.0\n",
       "21292  she was not prevented from offering, nor you f...    1.0\n",
       "54584  what I have to tell you. I must confess myself...    1.0\n",
       "46070  distinguished by his sisters. Jane was as much...    1.0\n",
       "55612  were sensible of your own good, you would not ...    1.0\n",
       "40603  \"Good God!\" she cried.--\"Well!\"--Then having r...    1.0\n",
       "13716  attention; and though latterly, from some hint...    1.0\n",
       "31773  The plan was that she should be brought up for...    1.0\n",
       "44473  and have very much distressed him. The alterat...    1.0\n",
       "\n",
       "[78261 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ftaV_67QeF8A",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173.0
    },
    "outputId": "938ba751-a35d-4099-e651-bf58416cacf3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10385</td>\n",
       "      <td>10308</td>\n",
       "      <td>\"Yes.\"</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>67876</td>\n",
       "      <td>67289</td>\n",
       "      <td>Churchhill.</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text                         \n",
       "       count unique          top freq\n",
       "label                                \n",
       "0.0    10385  10308       \"Yes.\"   12\n",
       "1.0    67876  67289  Churchhill.   17"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "eEtHO1Nk_r8T",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "text = merge['text']\n",
    "target = merge['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "jV6YjM8pAh1m",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class naivebayes(object):\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "\n",
    "      self.num_messages = {}\n",
    "      self.log_class_priors = {}\n",
    "      self.word_counts = {}\n",
    "      self.vocab = set()\n",
    " \n",
    "      n = len(X)\n",
    "      self.num_messages['jane'] = sum(1 for label in Y if label == 1)\n",
    "      self.num_messages['conan'] = sum(1 for label in Y if label == 0)\n",
    "      #here the log priors are calculated \n",
    "      self.log_class_priors['jane'] = math.log(self.num_messages['jane'] / n)\n",
    "      self.log_class_priors['conan'] = math.log(self.num_messages['conan'] / n)\n",
    "      self.word_counts['jane'] = {}\n",
    "      self.word_counts['conan'] = {}\n",
    "\n",
    "      for x, y in zip(X, Y):\n",
    "          c = 'jane' if y == 1 else 'conan'\n",
    "          counts = self.get_word_counts(self.tokenize(x))\n",
    "          for word, count in counts.items():\n",
    "              if word not in self.vocab:\n",
    "                  self.vocab.add(word)\n",
    "              if word not in self.word_counts[c]:\n",
    "                  self.word_counts[c][word] = 0.0\n",
    "\n",
    "              self.word_counts[c][word] += count\n",
    "    def clean(self, s):\n",
    "        translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.translate(translator)\n",
    " \n",
    "    def tokenize(self, text):\n",
    "        text = self.clean(text).lower()\n",
    "        return re.split(\"\\W+\", text) #we tokenize the lines in the text\n",
    " \n",
    "    def get_word_counts(self, words):\n",
    "        word_counts = {}\n",
    "        for word in words:\n",
    "            word_counts[word] = word_counts.get(word, 0.0) + 1.0\n",
    "        return word_counts #we get the word counts of all the words present in the lines\n",
    "    \n",
    "    def predict(self, X):\n",
    "      result = []\n",
    "      for x in X:\n",
    "          counts = self.get_word_counts(self.tokenize(x))\n",
    "          j_score = 0\n",
    "          c_score = 0\n",
    "          for word, _ in counts.items():\n",
    "              if word not in self.vocab: continue\n",
    "\n",
    "              # here we add laplace smoothing which will prevent divison by 0 and also add\n",
    "              # log to help with the computation of the values\n",
    "              log_w_given_j = math.log( (self.word_counts['jane'].get(word, 0.0) + 1) / (self.num_messages['jane'] + len(self.vocab)) )\n",
    "              log_w_given_c = math.log( (self.word_counts['conan'].get(word, 0.0) + 1) / (self.num_messages['conan'] + len(self.vocab)) )\n",
    "\n",
    "              j_score += log_w_given_j\n",
    "              c_score += log_w_given_c\n",
    "\n",
    "          j_score += self.log_class_priors['jane']\n",
    "          c_score += self.log_class_priors['conan']\n",
    "\n",
    "          if j_score > c_score: #here we check if proba of jane is > prob of conan we append the results  appropriately\n",
    "              result.append(1)\n",
    "          else:\n",
    "              result.append(0)\n",
    "      return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0loQHUJPac9q",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "Mnn= naivebayes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ROzdP-GCBqLn",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "naive_bayes = naivebayes()\n",
    "naive_bayes.fit(text[100:], target[100:]) #we call the fit function on all the lines except the first \n",
    "pred_Values = naive_bayes.predict(text[:1000]) #we predict for the the first 1000 lines\n",
    "true_values = target[:1000]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "PCbo4KLtG6TY",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "d48139e5-0609-4f8e-d6c8-64f14236d14d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 12, 1: 988})"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(pred_Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "PwAYfw0VMsRQ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "7bc853ca-d52c-48db-c4b9-862216062b4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 138, 1.0: 862})"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "qR3t_C67Ef4t",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "47469978-5f04-4033-92b8-e44683b7bfca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pred_Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "oumCD0MZE1Ds",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "ea914719-46ff-4bae-cc5d-44f32fe1e056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "x9g9zS0IE6N5",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "ZakhDkTlFcii",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "3abe3f7e-5a3b-424f-961a-f778c5634a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 87.4 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is:\",accuracy_score(true_values,pred_Values)*100,'%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "asg-2 , q-2",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
